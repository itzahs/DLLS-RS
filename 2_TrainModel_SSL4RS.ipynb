{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itzahs/SSL-for-RS/blob/main/2_TrainModel_SSL4RS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ **Semi-Supervised Learning for Remote Sensing (SSL4RS) Workshop** üõ∞Ô∏è\n",
        "\n",
        "## üìÇ Section 1 - Get Data & Software: Dataset Download & Augmentation\n",
        "## üõ†Ô∏è Section 2 - Train Model: Implementing FixMatch Algorithm with PyTorch\n",
        "## üìä Section 3 - Model Evaluation: Analyzing Accuracy & Computational Cost from Log Files\n",
        "## üìà Section 4 - Model Inference: Classification Accuracy and Embeddings Visualization\n"
      ],
      "metadata": {
        "id": "6ZT8hosUQMrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìö Setting Up the Working Folder & Importing Required Packages\n"
      ],
      "metadata": {
        "id": "G0El0qJbZ7g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Monitor the GPU usage\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JR-1kDgYMX2",
        "outputId": "10265336-cf59-4977-9b4e-f1511c64822a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 20 08:15:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzyWCwb4IIkl",
        "outputId": "62da7bb0-3ad2-4b07-b6ea-0add94b24fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set working folder as default\n",
        "%cd \"/content/drive/MyDrive/SSL4RS\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm9aZ1AwZyEm",
        "outputId": "cdbed3f4-e921-4d09-b710-2e6be022c09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SSL4RS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmFDSqGoWWqM",
        "outputId": "b69a8b63-5c3b-4c7c-b528-a84c02320455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification-SemiCLS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß **Code Modifications and Library Requirements**\n",
        "\n",
        "This section provides an overview of essential code modifications and library requirements to ensure the software operates smoothly. Key points include:\n",
        "\n",
        "#### **Code Adjustments**\n",
        "\n",
        "To enable seamless operation within a Jupyter notebook environment, specific code adjustments are necessary. These adjustments are detailed below:\n",
        "\n",
        "1. **Modifications to `./Classification-SemiCLS/dataset/builder.py`**\n",
        "\n",
        "   - **Ignore `.ipynb_checkpoints`**: In `dataset/builder.py` (lines 82-92), implement code to ignore `.ipynb_checkpoints` as needed.\n",
        "\n",
        "2. **Modifications to `./Classification-SemiCLS/train_semi.py`**\n",
        "\n",
        "   - **Update 'labeled.next()'**: In `train_semi.py` (lines 444 & 450), replace `labeled.next()` with `next(labeled)`.\n",
        "\n",
        "   - **Update 'unlabeled.next'**: In `train_semi.py` (lines 453 & 459), replace `unlabeled.next` with `next(unlabeled)`.\n",
        "\n",
        "#### **Library Dependencies**\n",
        "\n",
        "To ensure compatibility and proper functionality, it is essential to list the required libraries along with their versions.\n",
        "\n"
      ],
      "metadata": {
        "id": "BlotIX9LfFWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifications to ./Classification-SemiCLS/dataset/builder.py\n",
        "builder_path = \"./Classification-SemiCLS/dataset/builder.py\"\n",
        "\n",
        "# Define the content to be added\n",
        "new_content = \"\"\"\n",
        "        import os\n",
        "        # check if .ipynb_checkpoints is in root, and exclude it\n",
        "        root = os.path.join(cfg.root, '')\n",
        "        if os.path.isdir(os.path.join(root, \".ipynb_checkpoints\")):\n",
        "            exclude_dir = os.path.join(root, \".ipynb_checkpoints\")\n",
        "        else:\n",
        "            exclude_dir = None\n",
        "\"\"\"\n",
        "\n",
        "# Read the content of the file\n",
        "with open(builder_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Check if the new content is already present in the file\n",
        "if new_content.strip() not in content:\n",
        "    # Find the location to insert the new content after \"else:\"\n",
        "    insert_index = content.find(\"else:\")\n",
        "    if insert_index == -1:\n",
        "        raise ValueError(\"Failed to find the insertion point after 'else:'.\")\n",
        "\n",
        "    # Find the end of the line for the \"else:\" statement\n",
        "    end_of_line = content.find(\"\\n\", insert_index)\n",
        "    if end_of_line == -1:\n",
        "        raise ValueError(\"Failed to find the end of the line for 'else:'.\")\n",
        "\n",
        "    # Insert the new content after the \"else:\" block and before the next line\n",
        "    modified_content = content[:end_of_line] + \"\\n\" + new_content + content[end_of_line:]\n",
        "\n",
        "    # Write the modified content back to the file\n",
        "    with open(builder_path, 'w') as file:\n",
        "        file.write(modified_content)\n",
        "\n",
        "    print(\"Modifications applied successfully.\")\n",
        "else:\n",
        "    print(\"Content is already present in the file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHqb-r90mVt9",
        "outputId": "4e7a689b-3c28-44dc-b2b6-71f67e8b5a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modifications applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifications to ./Classification-SemiCLS/train_semi.py\n",
        "train_semi_path = \"./Classification-SemiCLS/train_semi.py\"\n",
        "\n",
        "# Read the content of the file\n",
        "with open(train_semi_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Modify lines as needed\n",
        "modified_lines = []\n",
        "for line in lines:\n",
        "    if \"data_x = labeled_iter.next()\" in line:\n",
        "        modified_lines.append(line.replace(\".next()\", \" = next(labeled_iter)\\n\"))\n",
        "    elif \"data_u = unlabeled_iter.next()\" in line:\n",
        "        modified_lines.append(line.replace(\".next()\", \" = next(unlabeled_iter)\\n\"))\n",
        "    elif \"from mmcv import Config\" in line:\n",
        "        modified_lines.append(line.replace(\"from mmcv import Config\", \"from mmengine.config import Config\"))\n",
        "    else:\n",
        "        modified_lines.append(line)\n",
        "\n",
        "# Write the modified content back to the file\n",
        "with open(train_semi_path, 'w') as file:\n",
        "    file.writelines(modified_lines)\n",
        "\n",
        "print(\"Modifications applied successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WUMIsY0PEPI",
        "outputId": "34a49299-9360-4b69-ae28-7cdf729e6d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modifications applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Install the required libraries\n",
        "%%capture\n",
        "!pip install mmcv-lite # the version used to be mmcv-full and now it's mmcv-lite\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install apex\n",
        "!pip install tensorboardX\n",
        "!pip install tensorboard\n",
        "!pip install tensorrt\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "-e-YUNcVLDI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõ†Ô∏è **Configuration for Training with FixMatch Algorithm**\n",
        "\n",
        "The configuration code defines parameters for training a deep learning model on the UCM dataset using the FixMatch algorithm. Key details include:\n",
        "\n",
        "- **Model Architecture**: The model used is a wideresnet28x2.\n",
        "- **Hardware**: Training occurs on a single GPU with a batch size of 8.\n",
        "- **Labeled Samples**: Only 4 labeled samples per class are used for training.\n",
        "\n",
        "The training process comprises three main components:\n",
        "\n",
        "1. **Train**: This section specifies the algorithm, the number of training steps, and the loss function.\n",
        "2. **Model**: Details about the architecture of the model to be trained are provided.\n",
        "3. **Data**: This section covers the loading and preprocessing of the UCM dataset, including the number of labeled samples, batch size, and data augmentation pipeline.\n",
        "\n",
        "Other configurations encompass options like the learning rate scheduler, exponential moving average (EMA) of model parameters, automatic mixed precision (AMP) optimization, optimizer and logging/checkpointing settings."
      ],
      "metadata": {
        "id": "HLmCPlATO-l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset builder and training syntax\n",
        "\n",
        "For the code to work in a Jupyter notebook environment we need to make two modifications. First, Jupyter notebook creates .ipynb_checkpoints and we need to ignore them and then, make some changes in the code syntax.\n",
        "1. In dataset/builder.py (lines 15): Add import os\n",
        "2. In dataset/builder.py (lines 82-92): add check to ignore .ipynb_checkpoints.\n",
        "3. In train_semi.py (lines 444 & 450): Modify labeled.next() for next(labeled).\n",
        "4. In train_semi.py (lines 453 & 459): Modify unlabeled.next for next(unlabeled).\n"
      ],
      "metadata": {
        "id": "SkFV70X0q9XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the config file for UCM - 4 labeled examples per class - FixMatch\n",
        "\n",
        "%%writefile ./Classification-SemiCLS/configs/fm_ucm.py\n",
        "\n",
        "\"\"\" The Code is under Tencent Youtu Public Rule\"\"\"\n",
        "\n",
        "train = dict(eval_step=5,#1024\n",
        "             total_steps=5*20,#1024*512\n",
        "             trainer=dict(type=\"FixMatch\",\n",
        "                          threshold=0.95,\n",
        "                          T=1.,\n",
        "                          lambda_u=1.,\n",
        "                          loss_x=dict(\n",
        "                              type=\"cross_entropy\",\n",
        "                              reduction=\"mean\"),\n",
        "                          loss_u=dict(\n",
        "                              type=\"cross_entropy\",\n",
        "                              reduction=\"none\"),\n",
        "                          ))\n",
        "num_classes = 21\n",
        "\n",
        "model = dict(\n",
        "     type=\"wideresnet\",\n",
        "     depth=28,\n",
        "     widen_factor=2,\n",
        "     dropout=0,\n",
        "     num_classes=num_classes,\n",
        ")\n",
        "\n",
        "ucm_mean = (0.485, 0.456, 0.406)\n",
        "ucm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "data = dict(\n",
        "    type=\"MyDataset\",\n",
        "    num_workers=4,\n",
        "    num_labeled=84,\n",
        "    num_classes=num_classes,\n",
        "    batch_size=4,\n",
        "    expand_labels=False,\n",
        "    mu=7,\n",
        "\n",
        "    root=\"./data/UCM/Images\",\n",
        "    labeled_names_file=\"./data/UCM/Images/UCM_train.txt\",\n",
        "    test_names_file=\"./data/UCM/Images/UCM_test.txt\",\n",
        "    lpipelines=[[\n",
        "        dict(type=\"RandomHorizontalFlip\"),\n",
        "        dict(type=\"RandomResizedCrop\", size=224, scale=(0.2, 1.0)),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "    ]],\n",
        "    upipelinse=[[\n",
        "        dict(type=\"RandomHorizontalFlip\"),\n",
        "        dict(type=\"Resize\", size=256),\n",
        "        dict(type=\"CenterCrop\", size=224),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "        ],\n",
        "        [\n",
        "        dict(type=\"RandomHorizontalFlip\"),\n",
        "        dict(type=\"RandomResizedCrop\", size=224, scale=(0.2, 1.0)),\n",
        "        dict(type=\"RandAugmentMC\", n=2, m=10),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "    ]],\n",
        "    vpipeline=[\n",
        "        dict(type=\"Resize\", size=256),\n",
        "        dict(type=\"CenterCrop\", size=224),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "    ])\n",
        "\n",
        "scheduler = dict(\n",
        "    type='cosine_schedule_with_warmup',\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=train['total_steps']\n",
        ")\n",
        "\n",
        "ema = dict(use=True, pseudo_with_ema=False, decay=0.999)\n",
        "#apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "#\"See details at https://nvidia.github.io/apex/amp.html\n",
        "amp = dict(use=False, opt_level=\"O1\")\n",
        "\n",
        "log = dict(interval=1)\n",
        "ckpt = dict(interval=1)\n",
        "\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.03, momentum=0.9, weight_decay=0.0005, nesterov=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLR-cMAYFIPC",
        "outputId": "d8c139c2-9cfb-4a8f-f994-e7a61a2e2a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./configs/fm_ucm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üöÄ **Initiate the Training** üèãÔ∏è‚Äç‚ôÇÔ∏è\n"
      ],
      "metadata": {
        "id": "pS7Arvmk67lG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the parent directory (Classification-SemiCLS) to sys.path:\n",
        "# The list in Python that specifies the directories for modules and packages to import.\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/SSL4RS/Classification-SemiCLS')\n",
        "\n",
        "# Set working folder as default\n",
        "%cd \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CkUPwgQmLlG",
        "outputId": "887b8fec-acb1-4b6e-9823-994b620d3604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SSL4RS/Classification-SemiCLS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running UCM with Fixmatch baseline\n",
        "!python3 ./train_semi.py --cfg /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py --gpu-id 0 --out /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/fixmatch/fm_ucm --seed 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaLLa1xgklSK",
        "outputId": "6304676b-af9c-488f-94fd-4883ab6ddbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-20 08:18:08.941184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-20 08:18:09.899797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-20 08:18:37,643 - WARNING - root -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "2023-10-20 08:18:37,644 - INFO - root -   {'cfg': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py', 'gpu_id': 0, 'out': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/fixmatch/fm_ucm', 'pretrained': None, 'resume': '', 'seed': 5, 'use_BN': False, 'fp16': False, 'local_rank': -1, 'no_progress': False, 'other_args': '', 'writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x7b8c6c9e3be0>, 'amp': False, 'total_steps': 100, 'eval_steps': 5, 'world_size': 1, 'n_gpu': 1, 'device': device(type='cuda', index=0)}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-20 08:18:46,319 - INFO - models.wideresnet -   Model: WideResNet 28x2 proj Falsex64\n",
            "2023-10-20 08:18:46,400 - INFO - root -   wideresnet Total params: 1.47M\n",
            "2023-10-20 08:18:47,473 - INFO - root -   ***** Running training *****\n",
            "2023-10-20 08:18:47,474 - INFO - root -     Task = MyDataset\n",
            "2023-10-20 08:18:47,474 - INFO - root -     Num Label = 84\n",
            "2023-10-20 08:18:47,474 - INFO - root -     Num Epochs = 20\n",
            "2023-10-20 08:18:47,474 - INFO - root -     Batch size per GPU = 8\n",
            "2023-10-20 08:18:47,474 - INFO - root -     Total train batch size = 8\n",
            "2023-10-20 08:18:47,475 - INFO - root -     Total optimization steps = 100\n",
            "2023-10-20 08:18:47,475 - INFO - root -   Config (path: /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py): {'train': {'eval_step': 5, 'total_steps': 100, 'trainer': {'type': 'FixMatch', 'threshold': 0.95, 'T': 1.0, 'lambda_u': 1.0, 'loss_x': {'type': 'cross_entropy', 'reduction': 'mean'}, 'loss_u': {'type': 'cross_entropy', 'reduction': 'none'}, 'amp': False}}, 'num_classes': 21, 'model': {'type': 'wideresnet', 'depth': 28, 'widen_factor': 2, 'dropout': 0, 'num_classes': 21}, 'ucm_mean': (0.485, 0.456, 0.406), 'ucm_std': (0.229, 0.224, 0.225), 'data': {'type': 'MyDataset', 'num_workers': 4, 'num_labeled': 84, 'num_classes': 21, 'batch_size': 8, 'expand_labels': False, 'mu': 7, 'root': './data/UCM/Images', 'labeled_names_file': './data/UCM/Images/UCM_train.txt', 'test_names_file': './data/UCM/Images/UCM_test.txt', 'lpipelines': [[{'type': 'RandomHorizontalFlip'}, {'type': 'RandomResizedCrop', 'size': 224, 'scale': (0.2, 1.0)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}]], 'upipelinse': [[{'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': 256}, {'type': 'CenterCrop', 'size': 224}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}], [{'type': 'RandomHorizontalFlip'}, {'type': 'RandomResizedCrop', 'size': 224, 'scale': (0.2, 1.0)}, {'type': 'RandAugmentMC', 'n': 2, 'm': 10}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}]], 'vpipeline': [{'type': 'Resize', 'size': 256}, {'type': 'CenterCrop', 'size': 224}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}], 'eval_step': 5}, 'scheduler': {'type': 'cosine_schedule_with_warmup', 'num_warmup_steps': 0, 'num_training_steps': 100}, 'ema': {'use': True, 'pseudo_with_ema': False, 'decay': 0.999}, 'amp': {'use': False, 'opt_level': 'O1'}, 'log': {'interval': 1}, 'ckpt': {'interval': 1}, 'optimizer': {'type': 'SGD', 'lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'resume': '', 'seed': 5}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 620, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 266, in main\n",
            "    train(args, cfg, labeled_trainloader, unlabeled_trainloader, test_loader,\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 467, in train\n",
            "    loss_dict = model_trainer.compute_loss(\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/trainer/fixmatch.py\", line 100, in compute_loss\n",
            "    logits = model(inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/models/wideresnet.py\", line 167, in forward\n",
            "    feat = self.block2(feat)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/models/wideresnet.py\", line 75, in forward\n",
            "    return self.layer(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 215, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/models/wideresnet.py\", line 54, in forward\n",
            "    out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 168.81 MiB is free. Process 17505 has 14.58 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 1.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running UCM with Fixmatch baseline\n",
        "!python3 ./train_semi.py --cfg /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py --gpu-id 0 --out /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/fixmatch/fm_ucm --seed 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37SQSW9AFaTb",
        "outputId": "d2798e62-0ba9-45af-e1db-5605daf0495d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-20 08:26:13.330372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-20 08:26:14.268121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-20 08:26:16,890 - WARNING - root -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "2023-10-20 08:26:16,890 - INFO - root -   {'cfg': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py', 'gpu_id': 0, 'out': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/fixmatch/fm_ucm', 'pretrained': None, 'resume': '', 'seed': 5, 'use_BN': False, 'fp16': False, 'local_rank': -1, 'no_progress': False, 'other_args': '', 'writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x7d7952075270>, 'amp': False, 'total_steps': 100, 'eval_steps': 5, 'world_size': 1, 'n_gpu': 1, 'device': device(type='cuda', index=0)}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-20 08:26:16,958 - INFO - models.wideresnet -   Model: WideResNet 28x2 proj Falsex64\n",
            "2023-10-20 08:26:17,008 - INFO - root -   wideresnet Total params: 1.47M\n",
            "2023-10-20 08:26:17,320 - INFO - root -   ***** Running training *****\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Task = MyDataset\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Num Label = 84\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Num Epochs = 20\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Batch size per GPU = 4\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Total train batch size = 4\n",
            "2023-10-20 08:26:17,321 - INFO - root -     Total optimization steps = 100\n",
            "2023-10-20 08:26:17,321 - INFO - root -   Config (path: /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/fm_ucm.py): {'train': {'eval_step': 5, 'total_steps': 100, 'trainer': {'type': 'FixMatch', 'threshold': 0.95, 'T': 1.0, 'lambda_u': 1.0, 'loss_x': {'type': 'cross_entropy', 'reduction': 'mean'}, 'loss_u': {'type': 'cross_entropy', 'reduction': 'none'}, 'amp': False}}, 'num_classes': 21, 'model': {'type': 'wideresnet', 'depth': 28, 'widen_factor': 2, 'dropout': 0, 'num_classes': 21}, 'ucm_mean': (0.485, 0.456, 0.406), 'ucm_std': (0.229, 0.224, 0.225), 'data': {'type': 'MyDataset', 'num_workers': 4, 'num_labeled': 84, 'num_classes': 21, 'batch_size': 4, 'expand_labels': False, 'mu': 7, 'root': './data/UCM/Images', 'labeled_names_file': './data/UCM/Images/UCM_train.txt', 'test_names_file': './data/UCM/Images/UCM_test.txt', 'lpipelines': [[{'type': 'RandomHorizontalFlip'}, {'type': 'RandomResizedCrop', 'size': 224, 'scale': (0.2, 1.0)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}]], 'upipelinse': [[{'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': 256}, {'type': 'CenterCrop', 'size': 224}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}], [{'type': 'RandomHorizontalFlip'}, {'type': 'RandomResizedCrop', 'size': 224, 'scale': (0.2, 1.0)}, {'type': 'RandAugmentMC', 'n': 2, 'm': 10}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}]], 'vpipeline': [{'type': 'Resize', 'size': 256}, {'type': 'CenterCrop', 'size': 224}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}], 'eval_step': 5}, 'scheduler': {'type': 'cosine_schedule_with_warmup', 'num_warmup_steps': 0, 'num_training_steps': 100}, 'ema': {'use': True, 'pseudo_with_ema': False, 'decay': 0.999}, 'amp': {'use': False, 'opt_level': 'O1'}, 'log': {'interval': 1}, 'ckpt': {'interval': 1}, 'optimizer': {'type': 'SGD', 'lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'resume': '', 'seed': 5}\n",
            "2023-10-20 08:26:21,373 - INFO - root -   Train Epoch: 1/  20. Iter:    1/   5. LR: 0.0300 batch_time: 3.671 data_time: 1.738 loss: 2.916 loss_x: 2.916 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:24,591 - INFO - root -   Train Epoch: 1/  20. Iter:    2/   5. LR: 0.0300 batch_time: 3.444 data_time: 1.721 loss: 3.004 loss_x: 3.004 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:27,411 - INFO - root -   Train Epoch: 1/  20. Iter:    3/   5. LR: 0.0300 batch_time: 3.236 data_time: 1.584 loss: 2.921 loss_x: 2.921 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:30,147 - INFO - root -   Train Epoch: 1/  20. Iter:    4/   5. LR: 0.0300 batch_time: 3.111 data_time: 1.493 loss: 3.047 loss_x: 3.047 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:33,845 - INFO - root -   Train Epoch: 1/  20. Iter:    5/   5. LR: 0.0299 batch_time: 3.228 data_time: 1.622 loss: 3.062 loss_x: 3.062 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.010s.                     Batch: 0.038s. Loss: 18.7781. top1: 5.24. top5: 23.33. : 100% 263/263 [00:10<00:00, 26.06it/s]\n",
            "2023-10-20 08:26:43,940 - INFO - root -   Epoch 0 top-1 acc: 5.24\n",
            "2023-10-20 08:26:43,940 - INFO - root -   Epoch 0 top-5 acc: 23.33\n",
            "2023-10-20 08:26:44,111 - INFO - root -   Best top-1 acc: 5.24\n",
            "2023-10-20 08:26:44,112 - INFO - root -   Mean top-1 acc: 5.24\n",
            "\n",
            "2023-10-20 08:26:46,930 - INFO - root -   Train Epoch: 2/  20. Iter:    1/   5. LR: 0.0299 batch_time: 2.817 data_time: 1.255 loss: 3.293 loss_x: 3.293 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:51,236 - INFO - root -   Train Epoch: 2/  20. Iter:    2/   5. LR: 0.0299 batch_time: 3.562 data_time: 1.987 loss: 3.122 loss_x: 3.122 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:54,440 - INFO - root -   Train Epoch: 2/  20. Iter:    3/   5. LR: 0.0298 batch_time: 3.443 data_time: 1.876 loss: 3.205 loss_x: 3.205 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:26:57,608 - INFO - root -   Train Epoch: 2/  20. Iter:    4/   5. LR: 0.0298 batch_time: 3.374 data_time: 1.811 loss: 2.995 loss_x: 2.995 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:00,858 - INFO - root -   Train Epoch: 2/  20. Iter:    5/   5. LR: 0.0297 batch_time: 3.349 data_time: 1.788 loss: 3.034 loss_x: 3.034 loss_u: 0.000 mask_prob: 0.007 pseudo_acc: 0.200 \n",
            "Test Iter:  263/ 263. Data: 0.006s.                     Batch: 0.034s. Loss: 16.1173. top1: 5.05. top5: 22.95. : 100% 263/263 [00:08<00:00, 29.30it/s]\n",
            "2023-10-20 08:27:09,835 - INFO - root -   Epoch 1 top-1 acc: 5.05\n",
            "2023-10-20 08:27:09,835 - INFO - root -   Epoch 1 top-5 acc: 22.95\n",
            "2023-10-20 08:27:09,952 - INFO - root -   Best top-1 acc: 5.24\n",
            "2023-10-20 08:27:09,954 - INFO - root -   Mean top-1 acc: 5.14\n",
            "\n",
            "2023-10-20 08:27:12,895 - INFO - root -   Train Epoch: 3/  20. Iter:    1/   5. LR: 0.0297 batch_time: 2.941 data_time: 1.389 loss: 4.380 loss_x: 4.380 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:15,862 - INFO - root -   Train Epoch: 3/  20. Iter:    2/   5. LR: 0.0296 batch_time: 2.954 data_time: 1.402 loss: 3.525 loss_x: 3.525 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:20,317 - INFO - root -   Train Epoch: 3/  20. Iter:    3/   5. LR: 0.0295 batch_time: 3.454 data_time: 1.896 loss: 3.196 loss_x: 3.196 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:23,257 - INFO - root -   Train Epoch: 3/  20. Iter:    4/   5. LR: 0.0294 batch_time: 3.326 data_time: 1.772 loss: 3.317 loss_x: 3.317 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:26,055 - INFO - root -   Train Epoch: 3/  20. Iter:    5/   5. LR: 0.0294 batch_time: 3.220 data_time: 1.672 loss: 3.212 loss_x: 3.212 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.007s.                     Batch: 0.034s. Loss: 12.8192. top1: 5.33. top5: 21.43. : 100% 263/263 [00:09<00:00, 29.09it/s]\n",
            "2023-10-20 08:27:35,099 - INFO - root -   Epoch 2 top-1 acc: 5.33\n",
            "2023-10-20 08:27:35,099 - INFO - root -   Epoch 2 top-5 acc: 21.43\n",
            "2023-10-20 08:27:35,294 - INFO - root -   Best top-1 acc: 5.33\n",
            "2023-10-20 08:27:35,300 - INFO - root -   Mean top-1 acc: 5.21\n",
            "\n",
            "2023-10-20 08:27:38,197 - INFO - root -   Train Epoch: 4/  20. Iter:    1/   5. LR: 0.0293 batch_time: 2.897 data_time: 1.364 loss: 2.594 loss_x: 2.593 loss_u: 0.000 mask_prob: 0.036 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:41,229 - INFO - root -   Train Epoch: 4/  20. Iter:    2/   5. LR: 0.0292 batch_time: 2.964 data_time: 1.434 loss: 3.354 loss_x: 3.353 loss_u: 0.000 mask_prob: 0.018 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:44,088 - INFO - root -   Train Epoch: 4/  20. Iter:    3/   5. LR: 0.0291 batch_time: 2.929 data_time: 1.400 loss: 3.400 loss_x: 3.400 loss_u: 0.000 mask_prob: 0.012 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:48,060 - INFO - root -   Train Epoch: 4/  20. Iter:    4/   5. LR: 0.0290 batch_time: 3.190 data_time: 1.645 loss: 3.471 loss_x: 3.471 loss_u: 0.000 mask_prob: 0.009 pseudo_acc: 0.000 \n",
            "2023-10-20 08:27:51,870 - INFO - root -   Train Epoch: 4/  20. Iter:    5/   5. LR: 0.0289 batch_time: 3.314 data_time: 1.763 loss: 3.415 loss_x: 3.415 loss_u: 0.000 mask_prob: 0.007 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.004s.                     Batch: 0.031s. Loss: 9.1075. top1: 5.90. top5: 19.90. : 100% 263/263 [00:08<00:00, 32.00it/s]\n",
            "2023-10-20 08:28:00,092 - INFO - root -   Epoch 3 top-1 acc: 5.90\n",
            "2023-10-20 08:28:00,092 - INFO - root -   Epoch 3 top-5 acc: 19.90\n",
            "2023-10-20 08:28:00,329 - INFO - root -   Best top-1 acc: 5.90\n",
            "2023-10-20 08:28:00,333 - INFO - root -   Mean top-1 acc: 5.38\n",
            "\n",
            "2023-10-20 08:28:04,050 - INFO - root -   Train Epoch: 5/  20. Iter:    1/   5. LR: 0.0288 batch_time: 3.716 data_time: 2.128 loss: 2.932 loss_x: 2.931 loss_u: 0.001 mask_prob: 0.036 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:06,899 - INFO - root -   Train Epoch: 5/  20. Iter:    2/   5. LR: 0.0286 batch_time: 3.283 data_time: 1.719 loss: 2.985 loss_x: 2.984 loss_u: 0.001 mask_prob: 0.018 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:10,065 - INFO - root -   Train Epoch: 5/  20. Iter:    3/   5. LR: 0.0285 batch_time: 3.244 data_time: 1.691 loss: 3.116 loss_x: 3.116 loss_u: 0.000 mask_prob: 0.012 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:13,223 - INFO - root -   Train Epoch: 5/  20. Iter:    4/   5. LR: 0.0284 batch_time: 3.223 data_time: 1.674 loss: 3.148 loss_x: 3.148 loss_u: 0.000 mask_prob: 0.009 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:16,854 - INFO - root -   Train Epoch: 5/  20. Iter:    5/   5. LR: 0.0282 batch_time: 3.304 data_time: 1.750 loss: 3.045 loss_x: 3.045 loss_u: 0.000 mask_prob: 0.007 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.005s.                     Batch: 0.033s. Loss: 6.5529. top1: 5.81. top5: 21.62. : 100% 263/263 [00:08<00:00, 30.43it/s]\n",
            "2023-10-20 08:28:25,500 - INFO - root -   Epoch 4 top-1 acc: 5.81\n",
            "2023-10-20 08:28:25,500 - INFO - root -   Epoch 4 top-5 acc: 21.62\n",
            "2023-10-20 08:28:25,603 - INFO - root -   Best top-1 acc: 5.90\n",
            "2023-10-20 08:28:25,604 - INFO - root -   Mean top-1 acc: 5.47\n",
            "\n",
            "2023-10-20 08:28:28,545 - INFO - root -   Train Epoch: 6/  20. Iter:    1/   5. LR: 0.0281 batch_time: 2.940 data_time: 1.400 loss: 3.336 loss_x: 3.336 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:32,496 - INFO - root -   Train Epoch: 6/  20. Iter:    2/   5. LR: 0.0280 batch_time: 3.445 data_time: 1.872 loss: 3.097 loss_x: 3.097 loss_u: 0.000 mask_prob: 0.036 pseudo_acc: 0.250 \n",
            "2023-10-20 08:28:35,818 - INFO - root -   Train Epoch: 6/  20. Iter:    3/   5. LR: 0.0278 batch_time: 3.404 data_time: 1.832 loss: 3.462 loss_x: 3.461 loss_u: 0.000 mask_prob: 0.036 pseudo_acc: 0.500 \n",
            "2023-10-20 08:28:38,746 - INFO - root -   Train Epoch: 6/  20. Iter:    4/   5. LR: 0.0276 batch_time: 3.285 data_time: 1.718 loss: 3.324 loss_x: 3.324 loss_u: 0.000 mask_prob: 0.036 pseudo_acc: 0.625 \n",
            "2023-10-20 08:28:41,916 - INFO - root -   Train Epoch: 6/  20. Iter:    5/   5. LR: 0.0275 batch_time: 3.262 data_time: 1.701 loss: 3.565 loss_x: 3.552 loss_u: 0.013 mask_prob: 0.050 pseudo_acc: 0.567 \n",
            "Test Iter:  263/ 263. Data: 0.007s.                     Batch: 0.034s. Loss: 4.9266. top1: 4.95. top5: 24.76. : 100% 263/263 [00:08<00:00, 29.24it/s]\n",
            "2023-10-20 08:28:50,913 - INFO - root -   Epoch 5 top-1 acc: 4.95\n",
            "2023-10-20 08:28:50,913 - INFO - root -   Epoch 5 top-5 acc: 24.76\n",
            "2023-10-20 08:28:51,029 - INFO - root -   Best top-1 acc: 5.90\n",
            "2023-10-20 08:28:51,033 - INFO - root -   Mean top-1 acc: 5.38\n",
            "\n",
            "2023-10-20 08:28:54,245 - INFO - root -   Train Epoch: 7/  20. Iter:    1/   5. LR: 0.0273 batch_time: 3.212 data_time: 1.643 loss: 3.626 loss_x: 3.626 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:28:57,245 - INFO - root -   Train Epoch: 7/  20. Iter:    2/   5. LR: 0.0271 batch_time: 3.106 data_time: 1.555 loss: 3.535 loss_x: 3.485 loss_u: 0.050 mask_prob: 0.018 pseudo_acc: 0.500 \n",
            "2023-10-20 08:28:59,998 - INFO - root -   Train Epoch: 7/  20. Iter:    3/   5. LR: 0.0270 batch_time: 2.988 data_time: 1.439 loss: 3.952 loss_x: 3.918 loss_u: 0.033 mask_prob: 0.012 pseudo_acc: 0.333 \n",
            "2023-10-20 08:29:04,464 - INFO - root -   Train Epoch: 7/  20. Iter:    4/   5. LR: 0.0268 batch_time: 3.358 data_time: 1.802 loss: 3.785 loss_x: 3.760 loss_u: 0.025 mask_prob: 0.009 pseudo_acc: 0.250 \n",
            "2023-10-20 08:29:07,189 - INFO - root -   Train Epoch: 7/  20. Iter:    5/   5. LR: 0.0266 batch_time: 3.231 data_time: 1.680 loss: 3.715 loss_x: 3.695 loss_u: 0.020 mask_prob: 0.007 pseudo_acc: 0.200 \n",
            "Test Iter:  263/ 263. Data: 0.005s.                     Batch: 0.032s. Loss: 4.1707. top1: 4.76. top5: 25.90. : 100% 263/263 [00:08<00:00, 30.81it/s]\n",
            "2023-10-20 08:29:15,726 - INFO - root -   Epoch 6 top-1 acc: 4.76\n",
            "2023-10-20 08:29:15,727 - INFO - root -   Epoch 6 top-5 acc: 25.90\n",
            "2023-10-20 08:29:15,863 - INFO - root -   Best top-1 acc: 5.90\n",
            "2023-10-20 08:29:15,864 - INFO - root -   Mean top-1 acc: 5.29\n",
            "\n",
            "2023-10-20 08:29:20,191 - INFO - root -   Train Epoch: 8/  20. Iter:    1/   5. LR: 0.0264 batch_time: 4.325 data_time: 2.739 loss: 2.899 loss_x: 2.899 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:23,399 - INFO - root -   Train Epoch: 8/  20. Iter:    2/   5. LR: 0.0262 batch_time: 3.767 data_time: 2.207 loss: 2.940 loss_x: 2.940 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:26,424 - INFO - root -   Train Epoch: 8/  20. Iter:    3/   5. LR: 0.0260 batch_time: 3.520 data_time: 1.969 loss: 2.815 loss_x: 2.815 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:29,642 - INFO - root -   Train Epoch: 8/  20. Iter:    4/   5. LR: 0.0258 batch_time: 3.444 data_time: 1.897 loss: 2.783 loss_x: 2.783 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:34,027 - INFO - root -   Train Epoch: 8/  20. Iter:    5/   5. LR: 0.0256 batch_time: 3.632 data_time: 2.076 loss: 2.994 loss_x: 2.994 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.004s.                     Batch: 0.031s. Loss: 3.7356. top1: 4.76. top5: 25.71. : 100% 263/263 [00:08<00:00, 31.77it/s]\n",
            "2023-10-20 08:29:42,305 - INFO - root -   Epoch 7 top-1 acc: 4.76\n",
            "2023-10-20 08:29:42,306 - INFO - root -   Epoch 7 top-5 acc: 25.71\n",
            "2023-10-20 08:29:42,423 - INFO - root -   Best top-1 acc: 5.90\n",
            "2023-10-20 08:29:42,426 - INFO - root -   Mean top-1 acc: 5.23\n",
            "\n",
            "2023-10-20 08:29:46,096 - INFO - root -   Train Epoch: 9/  20. Iter:    1/   5. LR: 0.0254 batch_time: 3.669 data_time: 2.089 loss: 2.984 loss_x: 2.984 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:49,536 - INFO - root -   Train Epoch: 9/  20. Iter:    2/   5. LR: 0.0251 batch_time: 3.555 data_time: 1.980 loss: 2.917 loss_x: 2.917 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:52,554 - INFO - root -   Train Epoch: 9/  20. Iter:    3/   5. LR: 0.0249 batch_time: 3.376 data_time: 1.814 loss: 2.906 loss_x: 2.906 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:55,469 - INFO - root -   Train Epoch: 9/  20. Iter:    4/   5. LR: 0.0247 batch_time: 3.261 data_time: 1.704 loss: 3.195 loss_x: 3.195 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:29:58,666 - INFO - root -   Train Epoch: 9/  20. Iter:    5/   5. LR: 0.0244 batch_time: 3.248 data_time: 1.693 loss: 3.091 loss_x: 3.091 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.006s.                     Batch: 0.034s. Loss: 3.4095. top1: 7.62. top5: 24.76. : 100% 263/263 [00:08<00:00, 29.39it/s]\n",
            "2023-10-20 08:30:07,618 - INFO - root -   Epoch 8 top-1 acc: 7.62\n",
            "2023-10-20 08:30:07,619 - INFO - root -   Epoch 8 top-5 acc: 24.76\n",
            "2023-10-20 08:30:07,805 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:30:07,807 - INFO - root -   Mean top-1 acc: 5.49\n",
            "\n",
            "2023-10-20 08:30:10,878 - INFO - root -   Train Epoch: 10/  20. Iter:    1/   5. LR: 0.0242 batch_time: 3.070 data_time: 1.497 loss: 2.279 loss_x: 2.279 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:30:14,181 - INFO - root -   Train Epoch: 10/  20. Iter:    2/   5. LR: 0.0240 batch_time: 3.187 data_time: 1.625 loss: 2.515 loss_x: 2.514 loss_u: 0.001 mask_prob: 0.018 pseudo_acc: 0.500 \n",
            "2023-10-20 08:30:18,685 - INFO - root -   Train Epoch: 10/  20. Iter:    3/   5. LR: 0.0237 batch_time: 3.626 data_time: 2.057 loss: 2.762 loss_x: 2.761 loss_u: 0.001 mask_prob: 0.012 pseudo_acc: 0.333 \n",
            "2023-10-20 08:30:21,471 - INFO - root -   Train Epoch: 10/  20. Iter:    4/   5. LR: 0.0234 batch_time: 3.416 data_time: 1.857 loss: 2.978 loss_x: 2.977 loss_u: 0.000 mask_prob: 0.018 pseudo_acc: 0.250 \n",
            "2023-10-20 08:30:24,487 - INFO - root -   Train Epoch: 10/  20. Iter:    5/   5. LR: 0.0232 batch_time: 3.336 data_time: 1.782 loss: 3.086 loss_x: 3.085 loss_u: 0.000 mask_prob: 0.014 pseudo_acc: 0.200 \n",
            "Test Iter:  263/ 263. Data: 0.007s.                     Batch: 0.034s. Loss: 3.2323. top1: 7.52. top5: 24.95. : 100% 263/263 [00:09<00:00, 28.96it/s]\n",
            "2023-10-20 08:30:33,571 - INFO - root -   Epoch 9 top-1 acc: 7.52\n",
            "2023-10-20 08:30:33,571 - INFO - root -   Epoch 9 top-5 acc: 24.95\n",
            "2023-10-20 08:30:33,678 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:30:33,680 - INFO - root -   Mean top-1 acc: 5.70\n",
            "\n",
            "2023-10-20 08:30:36,536 - INFO - root -   Train Epoch: 11/  20. Iter:    1/   5. LR: 0.0229 batch_time: 2.856 data_time: 1.318 loss: 4.171 loss_x: 4.171 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:30:39,781 - INFO - root -   Train Epoch: 11/  20. Iter:    2/   5. LR: 0.0227 batch_time: 3.051 data_time: 1.506 loss: 3.362 loss_x: 3.362 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:30:42,773 - INFO - root -   Train Epoch: 11/  20. Iter:    3/   5. LR: 0.0224 batch_time: 3.031 data_time: 1.487 loss: 3.296 loss_x: 3.296 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:30:46,975 - INFO - root -   Train Epoch: 11/  20. Iter:    4/   5. LR: 0.0221 batch_time: 3.324 data_time: 1.772 loss: 3.123 loss_x: 3.123 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:30:50,175 - INFO - root -   Train Epoch: 11/  20. Iter:    5/   5. LR: 0.0218 batch_time: 3.299 data_time: 1.751 loss: 2.999 loss_x: 2.999 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.005s.                     Batch: 0.032s. Loss: 3.1387. top1: 5.90. top5: 25.33. : 100% 263/263 [00:08<00:00, 31.03it/s]\n",
            "2023-10-20 08:30:58,652 - INFO - root -   Epoch 10 top-1 acc: 5.90\n",
            "2023-10-20 08:30:58,653 - INFO - root -   Epoch 10 top-5 acc: 25.33\n",
            "2023-10-20 08:30:58,808 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:30:58,809 - INFO - root -   Mean top-1 acc: 5.71\n",
            "\n",
            "2023-10-20 08:31:02,827 - INFO - root -   Train Epoch: 12/  20. Iter:    1/   5. LR: 0.0215 batch_time: 4.018 data_time: 2.443 loss: 3.315 loss_x: 3.315 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:05,960 - INFO - root -   Train Epoch: 12/  20. Iter:    2/   5. LR: 0.0213 batch_time: 3.575 data_time: 2.021 loss: 2.993 loss_x: 2.993 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:09,060 - INFO - root -   Train Epoch: 12/  20. Iter:    3/   5. LR: 0.0210 batch_time: 3.417 data_time: 1.868 loss: 2.817 loss_x: 2.817 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:11,911 - INFO - root -   Train Epoch: 12/  20. Iter:    4/   5. LR: 0.0207 batch_time: 3.275 data_time: 1.728 loss: 2.867 loss_x: 2.867 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:16,406 - INFO - root -   Train Epoch: 12/  20. Iter:    5/   5. LR: 0.0204 batch_time: 3.519 data_time: 1.963 loss: 2.793 loss_x: 2.793 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.004s.                     Batch: 0.031s. Loss: 3.0914. top1: 5.81. top5: 24.19. : 100% 263/263 [00:08<00:00, 31.87it/s]\n",
            "2023-10-20 08:31:24,661 - INFO - root -   Epoch 11 top-1 acc: 5.81\n",
            "2023-10-20 08:31:24,662 - INFO - root -   Epoch 11 top-5 acc: 24.19\n",
            "2023-10-20 08:31:24,769 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:31:24,772 - INFO - root -   Mean top-1 acc: 5.72\n",
            "\n",
            "2023-10-20 08:31:27,699 - INFO - root -   Train Epoch: 13/  20. Iter:    1/   5. LR: 0.0201 batch_time: 2.925 data_time: 1.371 loss: 2.091 loss_x: 2.091 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:31,656 - INFO - root -   Train Epoch: 13/  20. Iter:    2/   5. LR: 0.0198 batch_time: 3.441 data_time: 1.882 loss: 2.829 loss_x: 2.829 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:34,839 - INFO - root -   Train Epoch: 13/  20. Iter:    3/   5. LR: 0.0194 batch_time: 3.355 data_time: 1.802 loss: 2.718 loss_x: 2.718 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:37,998 - INFO - root -   Train Epoch: 13/  20. Iter:    4/   5. LR: 0.0191 batch_time: 3.306 data_time: 1.757 loss: 2.749 loss_x: 2.749 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:41,127 - INFO - root -   Train Epoch: 13/  20. Iter:    5/   5. LR: 0.0188 batch_time: 3.271 data_time: 1.722 loss: 2.884 loss_x: 2.884 loss_u: 0.000 mask_prob: 0.007 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.006s.                     Batch: 0.034s. Loss: 3.0677. top1: 5.81. top5: 24.10. : 100% 263/263 [00:08<00:00, 29.39it/s]\n",
            "2023-10-20 08:31:50,080 - INFO - root -   Epoch 12 top-1 acc: 5.81\n",
            "2023-10-20 08:31:50,081 - INFO - root -   Epoch 12 top-5 acc: 24.10\n",
            "2023-10-20 08:31:50,183 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:31:50,184 - INFO - root -   Mean top-1 acc: 5.73\n",
            "\n",
            "2023-10-20 08:31:52,986 - INFO - root -   Train Epoch: 14/  20. Iter:    1/   5. LR: 0.0185 batch_time: 2.801 data_time: 1.261 loss: 2.877 loss_x: 2.877 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:31:56,239 - INFO - root -   Train Epoch: 14/  20. Iter:    2/   5. LR: 0.0182 batch_time: 3.027 data_time: 1.486 loss: 3.588 loss_x: 3.588 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:00,199 - INFO - root -   Train Epoch: 14/  20. Iter:    3/   5. LR: 0.0178 batch_time: 3.338 data_time: 1.777 loss: 3.555 loss_x: 3.555 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:03,431 - INFO - root -   Train Epoch: 14/  20. Iter:    4/   5. LR: 0.0175 batch_time: 3.312 data_time: 1.751 loss: 3.399 loss_x: 3.399 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:06,211 - INFO - root -   Train Epoch: 14/  20. Iter:    5/   5. LR: 0.0172 batch_time: 3.205 data_time: 1.650 loss: 3.347 loss_x: 3.347 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.006s.                     Batch: 0.034s. Loss: 3.0556. top1: 5.05. top5: 26.10. : 100% 263/263 [00:09<00:00, 29.06it/s]\n",
            "2023-10-20 08:32:15,263 - INFO - root -   Epoch 13 top-1 acc: 5.05\n",
            "2023-10-20 08:32:15,264 - INFO - root -   Epoch 13 top-5 acc: 26.10\n",
            "2023-10-20 08:32:15,363 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:32:15,365 - INFO - root -   Mean top-1 acc: 5.68\n",
            "\n",
            "2023-10-20 08:32:18,652 - INFO - root -   Train Epoch: 15/  20. Iter:    1/   5. LR: 0.0168 batch_time: 3.286 data_time: 1.714 loss: 2.660 loss_x: 2.660 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:21,518 - INFO - root -   Train Epoch: 15/  20. Iter:    2/   5. LR: 0.0165 batch_time: 3.076 data_time: 1.521 loss: 2.868 loss_x: 2.868 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:24,458 - INFO - root -   Train Epoch: 15/  20. Iter:    3/   5. LR: 0.0161 batch_time: 3.031 data_time: 1.482 loss: 2.897 loss_x: 2.897 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:27,511 - INFO - root -   Train Epoch: 15/  20. Iter:    4/   5. LR: 0.0158 batch_time: 3.036 data_time: 1.488 loss: 2.820 loss_x: 2.820 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:31,005 - INFO - root -   Train Epoch: 15/  20. Iter:    5/   5. LR: 0.0154 batch_time: 3.128 data_time: 1.577 loss: 2.768 loss_x: 2.768 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.004s.                     Batch: 0.031s. Loss: 3.0488. top1: 4.95. top5: 25.71. : 100% 263/263 [00:08<00:00, 32.04it/s]\n",
            "2023-10-20 08:32:39,216 - INFO - root -   Epoch 14 top-1 acc: 4.95\n",
            "2023-10-20 08:32:39,217 - INFO - root -   Epoch 14 top-5 acc: 25.71\n",
            "2023-10-20 08:32:39,319 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:32:39,322 - INFO - root -   Mean top-1 acc: 5.63\n",
            "\n",
            "2023-10-20 08:32:43,455 - INFO - root -   Train Epoch: 16/  20. Iter:    1/   5. LR: 0.0151 batch_time: 4.131 data_time: 2.519 loss: 2.529 loss_x: 2.529 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:47,066 - INFO - root -   Train Epoch: 16/  20. Iter:    2/   5. LR: 0.0147 batch_time: 3.871 data_time: 2.275 loss: 2.841 loss_x: 2.841 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:50,220 - INFO - root -   Train Epoch: 16/  20. Iter:    3/   5. LR: 0.0143 batch_time: 3.632 data_time: 2.058 loss: 3.082 loss_x: 3.082 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:53,244 - INFO - root -   Train Epoch: 16/  20. Iter:    4/   5. LR: 0.0140 batch_time: 3.480 data_time: 1.916 loss: 2.888 loss_x: 2.888 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:32:56,436 - INFO - root -   Train Epoch: 16/  20. Iter:    5/   5. LR: 0.0136 batch_time: 3.423 data_time: 1.861 loss: 2.932 loss_x: 2.932 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.006s.                     Batch: 0.033s. Loss: 3.0448. top1: 4.95. top5: 25.62. : 100% 263/263 [00:08<00:00, 29.78it/s]\n",
            "2023-10-20 08:33:05,270 - INFO - root -   Epoch 15 top-1 acc: 4.95\n",
            "2023-10-20 08:33:05,270 - INFO - root -   Epoch 15 top-5 acc: 25.62\n",
            "2023-10-20 08:33:05,376 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:33:05,376 - INFO - root -   Mean top-1 acc: 5.59\n",
            "\n",
            "2023-10-20 08:33:08,558 - INFO - root -   Train Epoch: 17/  20. Iter:    1/   5. LR: 0.0133 batch_time: 3.179 data_time: 1.613 loss: 2.986 loss_x: 2.986 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:12,369 - INFO - root -   Train Epoch: 17/  20. Iter:    2/   5. LR: 0.0129 batch_time: 3.495 data_time: 1.914 loss: 2.920 loss_x: 2.920 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:16,071 - INFO - root -   Train Epoch: 17/  20. Iter:    3/   5. LR: 0.0125 batch_time: 3.564 data_time: 1.984 loss: 2.636 loss_x: 2.636 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:19,288 - INFO - root -   Train Epoch: 17/  20. Iter:    4/   5. LR: 0.0121 batch_time: 3.477 data_time: 1.908 loss: 2.641 loss_x: 2.641 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:22,309 - INFO - root -   Train Epoch: 17/  20. Iter:    5/   5. LR: 0.0118 batch_time: 3.386 data_time: 1.823 loss: 2.685 loss_x: 2.685 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.007s.                     Batch: 0.035s. Loss: 3.0422. top1: 5.05. top5: 25.71. : 100% 263/263 [00:09<00:00, 28.55it/s]\n",
            "2023-10-20 08:33:31,523 - INFO - root -   Epoch 16 top-1 acc: 5.05\n",
            "2023-10-20 08:33:31,523 - INFO - root -   Epoch 16 top-5 acc: 25.71\n",
            "2023-10-20 08:33:31,637 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:33:31,641 - INFO - root -   Mean top-1 acc: 5.56\n",
            "\n",
            "2023-10-20 08:33:34,820 - INFO - root -   Train Epoch: 18/  20. Iter:    1/   5. LR: 0.0114 batch_time: 3.179 data_time: 1.620 loss: 2.842 loss_x: 2.842 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:37,889 - INFO - root -   Train Epoch: 18/  20. Iter:    2/   5. LR: 0.0110 batch_time: 3.124 data_time: 1.575 loss: 3.176 loss_x: 3.176 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:41,209 - INFO - root -   Train Epoch: 18/  20. Iter:    3/   5. LR: 0.0106 batch_time: 3.189 data_time: 1.627 loss: 3.074 loss_x: 3.074 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:45,593 - INFO - root -   Train Epoch: 18/  20. Iter:    4/   5. LR: 0.0102 batch_time: 3.488 data_time: 1.920 loss: 2.974 loss_x: 2.974 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:33:48,538 - INFO - root -   Train Epoch: 18/  20. Iter:    5/   5. LR: 0.0098 batch_time: 3.379 data_time: 1.820 loss: 3.336 loss_x: 3.336 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.005s.                     Batch: 0.033s. Loss: 3.0405. top1: 5.24. top5: 25.52. : 100% 263/263 [00:08<00:00, 30.13it/s]\n",
            "2023-10-20 08:33:57,270 - INFO - root -   Epoch 17 top-1 acc: 5.24\n",
            "2023-10-20 08:33:57,271 - INFO - root -   Epoch 17 top-5 acc: 25.52\n",
            "2023-10-20 08:33:57,401 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:33:57,412 - INFO - root -   Mean top-1 acc: 5.54\n",
            "\n",
            "2023-10-20 08:34:01,352 - INFO - root -   Train Epoch: 19/  20. Iter:    1/   5. LR: 0.0094 batch_time: 3.940 data_time: 2.359 loss: 2.949 loss_x: 2.949 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:04,569 - INFO - root -   Train Epoch: 19/  20. Iter:    2/   5. LR: 0.0090 batch_time: 3.578 data_time: 2.021 loss: 2.894 loss_x: 2.894 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:07,848 - INFO - root -   Train Epoch: 19/  20. Iter:    3/   5. LR: 0.0087 batch_time: 3.478 data_time: 1.916 loss: 3.163 loss_x: 3.163 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:11,734 - INFO - root -   Train Epoch: 19/  20. Iter:    4/   5. LR: 0.0083 batch_time: 3.580 data_time: 2.009 loss: 2.859 loss_x: 2.859 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:15,983 - INFO - root -   Train Epoch: 19/  20. Iter:    5/   5. LR: 0.0079 batch_time: 3.714 data_time: 2.142 loss: 2.728 loss_x: 2.728 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.004s.                     Batch: 0.031s. Loss: 3.0394. top1: 5.33. top5: 26.19. : 100% 263/263 [00:08<00:00, 32.08it/s]\n",
            "2023-10-20 08:34:24,183 - INFO - root -   Epoch 18 top-1 acc: 5.33\n",
            "2023-10-20 08:34:24,184 - INFO - root -   Epoch 18 top-5 acc: 26.19\n",
            "2023-10-20 08:34:24,286 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:34:24,287 - INFO - root -   Mean top-1 acc: 5.53\n",
            "\n",
            "2023-10-20 08:34:27,571 - INFO - root -   Train Epoch: 20/  20. Iter:    1/   5. LR: 0.0075 batch_time: 3.282 data_time: 1.674 loss: 2.534 loss_x: 2.534 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:31,754 - INFO - root -   Train Epoch: 20/  20. Iter:    2/   5. LR: 0.0071 batch_time: 3.733 data_time: 2.138 loss: 2.959 loss_x: 2.959 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:34,842 - INFO - root -   Train Epoch: 20/  20. Iter:    3/   5. LR: 0.0067 batch_time: 3.518 data_time: 1.941 loss: 2.848 loss_x: 2.848 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:37,859 - INFO - root -   Train Epoch: 20/  20. Iter:    4/   5. LR: 0.0063 batch_time: 3.393 data_time: 1.827 loss: 3.017 loss_x: 3.017 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:34:40,911 - INFO - root -   Train Epoch: 20/  20. Iter:    5/   5. LR: 0.0059 batch_time: 3.324 data_time: 1.762 loss: 3.036 loss_x: 3.036 loss_u: 0.000 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "Test Iter:  263/ 263. Data: 0.007s.                     Batch: 0.034s. Loss: 3.0386. top1: 5.52. top5: 26.67. : 100% 263/263 [00:09<00:00, 28.94it/s]\n",
            "2023-10-20 08:34:50,002 - INFO - root -   Epoch 19 top-1 acc: 5.52\n",
            "2023-10-20 08:34:50,003 - INFO - root -   Epoch 19 top-5 acc: 26.67\n",
            "2023-10-20 08:34:50,109 - INFO - root -   Best top-1 acc: 7.62\n",
            "2023-10-20 08:34:50,109 - INFO - root -   Mean top-1 acc: 5.53\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõ†Ô∏è **Configuration for Training with CoMatch Algorithm**"
      ],
      "metadata": {
        "id": "6RhDyWRs3r2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the config file for UCM - 4 labeled examples per class - CoMatch\n",
        "\n",
        "%%writefile /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/comatch_ucm.py\n",
        "\n",
        "\"\"\" The Code is under Tencent Youtu Public Rule\"\"\"\n",
        "\n",
        "train = dict(\n",
        "    eval_step=1024,\n",
        "    total_steps=2**10*512,\n",
        "    trainer=dict(\n",
        "        type='CoMatch',\n",
        "        threshold=0.95, #pseudolabel threshold\n",
        "        queue_batch=5,  #memory buffer\n",
        "        contrast_threshold=0.8, #similarity matrix\n",
        "        da_len=32, #distribution alignment\n",
        "        T=0.2, # temperature\n",
        "        alpha=0.9,# 1-alpha for memory smoothed pseudo label\n",
        "        lambda_u=1.0, #unlabeled loss\n",
        "        lambda_c=1.0, #contrastive loss\n",
        "        loss_x=dict(type=\"cross_entropy\", reduction=\"mean\"))) #supervised loss\n",
        "\n",
        "num_classes = 21\n",
        "\n",
        "model = dict(\n",
        "     #type='wideresnet', #config for wideresnet purposes\n",
        "     #depth=28,\n",
        "     #widen_factor=2, #reducing number of filters for memory\n",
        "     #dropout=0,\n",
        "     type=\"resnet18\", #config for resnet purposes\n",
        "     width=1,\n",
        "     in_channel=3,\n",
        "     num_class=num_classes,\n",
        "     proj=True,\n",
        "     low_dim=64, # projection head\n",
        ")\n",
        "\n",
        "# Obtained from Imagenet\n",
        "ucm_mean = [0.485, 0.456, 0.406]\n",
        "ucm_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "data = dict(\n",
        "    # Dataset configuration\n",
        "    type=\"MyDataset\", #customized dataset\n",
        "    num_workers=4,\n",
        "    num_labeled=84, #num_labeled/num_classes=labeled samples per class\n",
        "    num_classes=num_classes,\n",
        "    batch_size=32, #reducing batch for memory\n",
        "    expand_labels=False,\n",
        "    mu=7, #labeled to unlabeled data ratio\n",
        "\n",
        "    #input data folder\n",
        "    root=\"./data/UCM/Images\", #\"./Classification-SemiCLS/data/AID\",\n",
        "    labeled_names_file=\"./data/UCM/Images/UCM_train.txt\", #\"./Classification-SemiCLS/data/AID/AID_train.txt\",\n",
        "    test_names_file=\"./data/UCM/Images/UCM_test.txt\", #\"./Classification-SemiCLS/data/AID/AID_test.txt\",\n",
        "\n",
        "    # labeled data preprocessing\n",
        "    lpipelines=[[\n",
        "        dict(type=\"Resize\", size=64),\n",
        "        dict(type=\"RandomHorizontalFlip\", p=0.5),\n",
        "        #dict(type=\"RandomResizedCrop\", size=224, scale=(0.2, 1.0)),\n",
        "        dict(type=\"RandomResizedCrop\", size=60, scale=(0.2, 1.0)),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "    ]],\n",
        "\n",
        "    # unlabeled data preprocessing\n",
        "    upipelinse=[\n",
        "        # weak augmentation\n",
        "        [\n",
        "        dict(type=\"Resize\", size=64),\n",
        "        dict(type=\"RandomHorizontalFlip\"),\n",
        "        #dict(type=\"Resize\", size=256),\n",
        "        #dict(type=\"CenterCrop\", size=224),\n",
        "        dict(type=\"CenterCrop\", size=60),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "        ],\n",
        "\n",
        "        # strong augmentation 1\n",
        "        [\n",
        "            dict(type=\"Resize\", size=64),\n",
        "            dict(type=\"RandomHorizontalFlip\"),\n",
        "            #dict(type=\"RandomResizedCrop\", size=224, scale=(0.2, 1.0)),\n",
        "            dict(type=\"RandomResizedCrop\", size=60, scale=(0.2, 1.0)),\n",
        "            dict(type=\"RandAugmentMC\", n=2, m=10),\n",
        "            dict(type=\"ToTensor\"),\n",
        "            dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "        ],\n",
        "\n",
        "        # strong augmentation 2\n",
        "        [\n",
        "            dict(type=\"Resize\", size=64),\n",
        "            #dict(type=\"RandomResizedCrop\", size=224, scale=(0.2, 1.0)),\n",
        "            dict(type=\"RandomResizedCrop\", size=60, scale=(0.2, 1.0)),\n",
        "            dict(type=\"RandomHorizontalFlip\"),\n",
        "            dict(type=\"RandomApply\",\n",
        "                    transforms=[\n",
        "                        dict(type=\"ColorJitter\",\n",
        "                            brightness=0.4,\n",
        "                            contrast=0.4,\n",
        "                            saturation=0.4,\n",
        "                            hue=0.1),\n",
        "                    ],\n",
        "                    p=0.8),\n",
        "            dict(type=\"RandomGrayscale\", p=0.2),\n",
        "            dict(type=\"ToTensor\")\n",
        "        ]],\n",
        "\n",
        "    # validation data preprocessing\n",
        "    vpipeline=[\n",
        "        dict(type=\"Resize\", size=64),\n",
        "        #dict(type=\"Resize\", size=256),\n",
        "        #dict(type=\"CenterCrop\", size=224),\n",
        "        dict(type=\"CenterCrop\", size=60),\n",
        "        dict(type=\"ToTensor\"),\n",
        "        dict(type=\"Normalize\", mean=ucm_mean, std=ucm_std)\n",
        "    ])\n",
        "\n",
        "scheduler = dict(\n",
        "    type='cosine_schedule_with_warmup',\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=train['total_steps']\n",
        ")\n",
        "\n",
        "ema = dict(use=True, pseudo_with_ema=False, decay=0.999)\n",
        "#apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\" \"See details at https://nvidia.github.io/apex/amp.html\n",
        "amp = dict(use=False, opt_level=\"O1\")\n",
        "\n",
        "log = dict(interval=1)\n",
        "#log = dict(interval=512)\n",
        "ckpt = dict(interval=1)\n",
        "\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.03, momentum=0.9, weight_decay=0.0005, nesterov=True)\n"
      ],
      "metadata": {
        "id": "Sqzs9x-f3skt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1acc70d-4183-4788-cae7-c28c9288cc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/comatch_ucm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running UCM with Fixmatch baseline\n",
        "!python3 ./train_semi.py --cfg /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/comatch_ucm.py --gpu-id 0 --out /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/comatch/comatch_ucm --seed 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7giMMxo3S2-",
        "outputId": "84c196b0-4f27-4130-8715-38b3a4ba8341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-20 08:20:22.324534: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-20 08:20:23.251990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-20 08:20:25,753 - WARNING - root -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "2023-10-20 08:20:25,754 - INFO - root -   {'cfg': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/comatch_ucm.py', 'gpu_id': 0, 'out': '/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/results/comatch/comatch_ucm', 'pretrained': None, 'resume': '', 'seed': 5, 'use_BN': False, 'fp16': False, 'local_rank': -1, 'no_progress': False, 'other_args': '', 'writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x7bdb2ab15f30>, 'amp': False, 'total_steps': 524288, 'eval_steps': 1024, 'world_size': 1, 'n_gpu': 1, 'device': device(type='cuda', index=0)}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-20 08:20:26,005 - INFO - root -   resnet18 Total params: 12.37M\n",
            "2023-10-20 08:20:26,262 - INFO - root -   ***** Running training *****\n",
            "2023-10-20 08:20:26,262 - INFO - root -     Task = MyDataset\n",
            "2023-10-20 08:20:26,262 - INFO - root -     Num Label = 84\n",
            "2023-10-20 08:20:26,262 - INFO - root -     Num Epochs = 512\n",
            "2023-10-20 08:20:26,263 - INFO - root -     Batch size per GPU = 32\n",
            "2023-10-20 08:20:26,263 - INFO - root -     Total train batch size = 32\n",
            "2023-10-20 08:20:26,263 - INFO - root -     Total optimization steps = 524288\n",
            "2023-10-20 08:20:26,263 - INFO - root -   Config (path: /content/drive/MyDrive/SSL4RS/Classification-SemiCLS/configs/comatch_ucm.py): {'train': {'eval_step': 1024, 'total_steps': 524288, 'trainer': {'type': 'CoMatch', 'threshold': 0.95, 'queue_batch': 5, 'contrast_threshold': 0.8, 'da_len': 32, 'T': 0.2, 'alpha': 0.9, 'lambda_u': 1.0, 'lambda_c': 1.0, 'loss_x': {'type': 'cross_entropy', 'reduction': 'mean'}, 'amp': False}}, 'num_classes': 21, 'model': {'type': 'resnet18', 'width': 1, 'in_channel': 3, 'num_class': 21, 'proj': True, 'low_dim': 64}, 'ucm_mean': [0.485, 0.456, 0.406], 'ucm_std': [0.229, 0.224, 0.225], 'data': {'type': 'MyDataset', 'num_workers': 4, 'num_labeled': 84, 'num_classes': 21, 'batch_size': 32, 'expand_labels': False, 'mu': 7, 'root': './data/UCM/Images', 'labeled_names_file': './data/UCM/Images/UCM_train.txt', 'test_names_file': './data/UCM/Images/UCM_test.txt', 'lpipelines': [[{'type': 'Resize', 'size': 64}, {'type': 'RandomHorizontalFlip', 'p': 0.5}, {'type': 'RandomResizedCrop', 'size': 60, 'scale': (0.2, 1.0)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}]], 'upipelinse': [[{'type': 'Resize', 'size': 64}, {'type': 'RandomHorizontalFlip'}, {'type': 'CenterCrop', 'size': 60}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}], [{'type': 'Resize', 'size': 64}, {'type': 'RandomHorizontalFlip'}, {'type': 'RandomResizedCrop', 'size': 60, 'scale': (0.2, 1.0)}, {'type': 'RandAugmentMC', 'n': 2, 'm': 10}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}], [{'type': 'Resize', 'size': 64}, {'type': 'RandomResizedCrop', 'size': 60, 'scale': (0.2, 1.0)}, {'type': 'RandomHorizontalFlip'}, {'type': 'RandomApply', 'transforms': [{'type': 'ColorJitter', 'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}], 'p': 0.8}, {'type': 'RandomGrayscale', 'p': 0.2}, {'type': 'ToTensor'}]], 'vpipeline': [{'type': 'Resize', 'size': 64}, {'type': 'CenterCrop', 'size': 60}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}], 'eval_step': 1024}, 'scheduler': {'type': 'cosine_schedule_with_warmup', 'num_warmup_steps': 0, 'num_training_steps': 524288}, 'ema': {'use': True, 'pseudo_with_ema': False, 'decay': 0.999}, 'amp': {'use': False, 'opt_level': 'O1'}, 'log': {'interval': 1}, 'ckpt': {'interval': 1}, 'optimizer': {'type': 'SGD', 'lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True}, 'resume': '', 'seed': 5}\n",
            "2023-10-20 08:22:29,280 - INFO - root -   Train Epoch: 1/ 512. Iter:    1/1024. LR: 0.0300 batch_time: 122.843 data_time: 120.973 loss: 8.469 loss_x: 3.048 loss_u: 0.000 loss_c: 5.422 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:23:41,466 - INFO - root -   Train Epoch: 1/ 512. Iter:    2/1024. LR: 0.0300 batch_time: 97.514 data_time: 96.383 loss: 8.873 loss_x: 3.460 loss_u: 0.000 loss_c: 5.413 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:24:39,037 - INFO - root -   Train Epoch: 1/ 512. Iter:    3/1024. LR: 0.0300 batch_time: 84.200 data_time: 83.326 loss: 8.994 loss_x: 3.587 loss_u: 0.000 loss_c: 5.407 mask_prob: 0.000 pseudo_acc: 0.000 \n",
            "2023-10-20 08:24:59,145 - INFO - root -   Train Epoch: 1/ 512. Iter:    4/1024. LR: 0.0300 batch_time: 68.177 data_time: 67.438 loss: 8.975 loss_x: 3.567 loss_u: 0.003 loss_c: 5.405 mask_prob: 0.008 pseudo_acc: 0.000 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 455, in train\n",
            "    data_u = unlabeled_iter = next(unlabeled_iter)\n",
            "TypeError: 'list' object is not an iterator\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 620, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 266, in main\n",
            "    train(args, cfg, labeled_trainloader, unlabeled_trainloader, test_loader,\n",
            "  File \"/content/drive/MyDrive/SSL4RS/Classification-SemiCLS/./train_semi.py\", line 462, in train\n",
            "    data_u = unlabeled_iter = next(unlabeled_iter)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1294, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}